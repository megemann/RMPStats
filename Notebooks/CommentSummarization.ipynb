{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': '203815-100', 'name': 'PSYCH100'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "professors_df = pd.read_csv('RateMyProfAnalysis/UMassReviews/professors_df_clean.csv')\n",
    "reviews_df = pd.read_csv('RateMyProfAnalysis/UMassReviews/reviews_df_clean_sentiment.csv')\n",
    "\n",
    "import json\n",
    "\n",
    "def clean_and_parse_json(x):\n",
    "    if not isinstance(x, str):\n",
    "        return x\n",
    "    try:\n",
    "        # First attempt: direct JSON parse\n",
    "        return json.loads(x)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            # Second attempt: Replace single quotes with double quotes\n",
    "            x = x.replace(\"'\", '\"')\n",
    "            return json.loads(x)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                # Third attempt: Use ast.literal_eval (safer than eval)\n",
    "                import ast\n",
    "                return ast.literal_eval(x)\n",
    "            except:\n",
    "                print(f\"Failed to parse: {x[:100]}...\")  # Print first 100 chars\n",
    "                return {}  # Return empty dict if all parsing attempts fail\n",
    "\n",
    "\n",
    "reviews_df['class_identifiers'] = reviews_df['class_identifiers'].apply(clean_and_parse_json)\n",
    "print(reviews_df['class_identifiers'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His lectures are basically him saying \"This should be obvious\" while teaching students concepts instead of carefully taking time to offer thorough explanations. Wilson was clearly lacking in social skills, and he held grudges against students who were genuinely trying to learn something new. Discussions and office hours were also poorly run, but he refused to take the class's weaknesses as a reflection on his pedagogy. Gotcha questions on exams, apathetic,disinterested, there aren't enough adjectives to describe the way this man treats people and runs his classroom.\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "def summarize_text(text, num_sentences=4):\n",
    "    stemmer = PorterStemmer()  # Initialize the NLTK stemmer\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summarizer.stemmer = stemmer  # Set the NLTK stemmer for the summarizer\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    return \" \".join([str(sentence) for sentence in summary])\n",
    "\n",
    "def get_all_reviews_for_professor(professor_id):\n",
    "    review_list = reviews_df[reviews_df['tid'] == professor_id]['comment'].tolist()\n",
    "    return \" \".join(review_list)\n",
    "\n",
    "def get_raw_reviews_for_professor(professor_id):\n",
    "    return reviews_df[reviews_df['tid'] == professor_id]\n",
    "\n",
    "print(summarize_text(get_all_reviews_for_professor(2936075)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However the class is a lot of work you MUST attend all lectures and keep up with readings to do well. You'll enjoy going to lecture, even though it' an 8AM (don't  skip, because a large chunk of test material centers around case studies discussed, videos shown, and diagnostic criteria presented in class. He makes the class interesting by sharing stories of his actual cases and provides three review sessions a week if you need help or extra credit. Didn't live up to my expectations after what I read on here...Nice guy, bit of an ego, but knows his stuff.\n"
     ]
    }
   ],
   "source": [
    "# Summarize by class\n",
    "def get_reviews_for_class(class_id):\n",
    "    review_list = []\n",
    "    for index, review in reviews_df.iterrows():  # Use iterrows to iterate over DataFrame rows\n",
    "        class_identifiers = review['class_identifiers']\n",
    "        if isinstance(class_identifiers, list):  # Ensure class_identifiers is a list\n",
    "            for item in class_identifiers:\n",
    "                if item.get('key') == class_id:\n",
    "                    review_list.append(review['comment'])\n",
    "    return \" \".join(review_list)\n",
    "\n",
    "def get_raw_reviews_for_class(class_id):\n",
    "    filtered_reviews = reviews_df[reviews_df['class_identifiers'].apply(lambda x: isinstance(x, list) and any(item.get('key') == class_id for item in x))]\n",
    "    return filtered_reviews\n",
    "\n",
    "print(summarize_text(get_reviews_for_class('83082-380')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However the class is a lot of work you MUST attend all lectures and keep up with readings to do well. You'll enjoy going to lecture, even though it' an 8AM (don't  skip, because a large chunk of test material centers around case studies discussed, videos shown, and diagnostic criteria presented in class. He makes the class interesting by sharing stories of his actual cases and provides three review sessions a week if you need help or extra credit. Didn't live up to my expectations after what I read on here...Nice guy, bit of an ego, but knows his stuff.\n",
      "His lectures are very engaging and makes it easy to get up early to go to class. His lectures are so interesting. Halgin's class is the best! Very funny as well for abnormal psych his class was very interesting and was one of my favorite classes that i have taken.\n",
      "I wish he was a professor for more psych classes because the amount I learned reflects how well he taught the material in a fun and interesting way, and made me want to go to class on a regular basis. We got there early just to get a seat (the auditorium was ALWAYS packed) Never missed a class, and the grades are earned, not too bad if you put in some effort, which is easy becase the material is so engaging. No Comments he's very experienced and knows a lot about his field which makes his class interesting No Comments No Comments No Comments only class i never missed one of He talks about himself a lot, but he's a great teacher. No Comments I NEVER missed this class it was so awsome Awesome professor, and gives the best and most interesting lectures No Comments No Comments Really good prof.  His lectures are interesting and guest lectures are great!\n",
      "I wish he was a professor for more psych classes because the amount I learned reflects how well he taught the material in a fun and interesting way, and made me want to go to class on a regular basis. Best class I have ever taken at Umass When I went to my adviser saying that I wanted to take abnormal with a different professor last spring, she suggested I wait and take it in the fall with Professor Halgin. We got there early just to get a seat (the auditorium was ALWAYS packed) Never missed a class, and the grades are earned, not too bad if you put in some effort, which is easy becase the material is so engaging. No Comments I NEVER missed this class it was so awsome Awesome professor, and gives the best and most interesting lectures No Comments No Comments Really good prof.  His lectures are interesting and guest lectures are great!\n"
     ]
    }
   ],
   "source": [
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "def summarize_text_compare(text, summarizer_type='lsa', sentences_count=4, language=\"english\"):\n",
    "    stemmer = PorterStemmer()  # Initialize the NLTK stemmer\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - text: string, the text to summarize\n",
    "    - summarizer_type: string, type of summarizer ('lsa', 'lexrank', 'luhn', or 'textrank')\n",
    "    - sentences_count: int, number of sentences in summary\n",
    "    - language: string, language of text\n",
    "    \n",
    "    Returns:\n",
    "    - string, the summarized text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Choose summarizer\n",
    "    if summarizer_type.lower() == 'lsa':\n",
    "        summarizer = LsaSummarizer()\n",
    "    elif summarizer_type.lower() == 'lexrank':\n",
    "        summarizer = LexRankSummarizer()\n",
    "    elif summarizer_type.lower() == 'luhn':\n",
    "        summarizer = LuhnSummarizer()\n",
    "    elif summarizer_type.lower() == 'textrank':\n",
    "        summarizer = TextRankSummarizer()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid summarizer type\")\n",
    "    \n",
    "    # Add stop words\n",
    "    summarizer.stemmer = stemmer\n",
    "    \n",
    "    # Create summary\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    \n",
    "    # Join sentences and return\n",
    "    return \" \".join([str(sentence) for sentence in summary])\n",
    "\n",
    "for item in ['lsa', 'lexrank', 'luhn', 'textrank']:\n",
    "    print(summarize_text_compare(get_reviews_for_class('83082-380'), item))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_sentiment': np.float64(0.36357141514265673), 'summary_sentiment': 0.20844155844155843}\n",
      "{'average_sentiment': np.float64(-0.0009831377042025218), 'summary_sentiment': 0.02121212121212121}\n"
     ]
    }
   ],
   "source": [
    "def sumy_sentiment_by_class(class_id):\n",
    "    # Get the reviews for the specified class\n",
    "    reviews = get_raw_reviews_for_class(class_id)\n",
    "    # Calculate the average sentiment of the reviews\n",
    "    import numpy as np\n",
    "    average_sentiment = np.mean(reviews['sentiment_polarity'].tolist())\n",
    "\n",
    "    from textblob import TextBlob\n",
    "    summary_sentiment = TextBlob(summarize_text_compare(get_reviews_for_class(class_id), 'lsa')).sentiment.polarity\n",
    "\n",
    "    return {'average_sentiment': average_sentiment, 'summary_sentiment': summary_sentiment}\n",
    "\n",
    "print(sumy_sentiment_by_class('83082-380'))\n",
    "\n",
    "def sumy_sentiment_by_professor(professor_id):\n",
    "    # Get the reviews for the specified professor\n",
    "    reviews = get_raw_reviews_for_professor(professor_id)\n",
    "\n",
    "    # Calculate the average sentiment of the reviews\n",
    "    import numpy as np\n",
    "    average_sentiment = np.mean(reviews['sentiment_polarity'].tolist())\n",
    "\n",
    "    from textblob import TextBlob\n",
    "    summary_sentiment = TextBlob(summarize_text_compare(get_all_reviews_for_professor(professor_id), 'lsa')).sentiment.polarity\n",
    "\n",
    "    return {'average_sentiment': average_sentiment, 'summary_sentiment': summary_sentiment}\n",
    "\n",
    "print(sumy_sentiment_by_professor(2936075))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sumy_sentiment_by_professor:   0%|                                                        | 0/1000 [00:00<?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sumy_sentiment_by_professor: 100%|█████████████████████████████████████████████████| 1000/1000 [02:09<00:00]\n",
      "Processing sumy_sentiment_by_class: 100%|███████████████████████████████████████████████████| 5486/5486 [2:12:33<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor Summary Evaluation\n",
      "Mean Absolute Error: 0.12279705164002853\n",
      "Median Absolute Error: 0.10215078298824566\n",
      "Standard Deviation of Absolute Error: 0.09396239068258952\n",
      "Class Summary Evaluation\n",
      "Mean Absolute Error: 0.08607122578162171\n",
      "Median Absolute Error: 0.0522152627465128\n",
      "Standard Deviation of Absolute Error: 0.10616727651244011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def summary_evaluation(summary_functions):\n",
    "\n",
    "    def run_summary_function(summary_function, data_list):\n",
    "        evaluation_list = []\n",
    "        from tqdm import tqdm\n",
    "        progress_bar = tqdm(total=len(data_list), desc=f\"Processing {summary_function.__name__}\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]')\n",
    "        for item in data_list:\n",
    "            evaluation_list.append(summary_function(item))\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()  # Close the progress bar after completion\n",
    "        \n",
    "        error_list = []\n",
    "        absolute_error_list = []\n",
    "        for item in evaluation_list:\n",
    "            error_list.append(item['average_sentiment'] - item['summary_sentiment'])\n",
    "            absolute_error_list.append(abs(item['average_sentiment'] - item['summary_sentiment']))\n",
    "\n",
    "        return {'error_list': error_list, 'absolute_error_list': absolute_error_list}\n",
    "\n",
    "    classes = []\n",
    "\n",
    "    for review in reviews_df['class_identifiers']:\n",
    "        for item in review:\n",
    "            classes.append(item['key'])\n",
    "\n",
    "    unique_classes = list(set(classes))\n",
    "    return [run_summary_function(summary_functions[0], professors_df['id']), run_summary_function(summary_functions[1], unique_classes)]\n",
    "\n",
    "\n",
    "errors = summary_evaluation([sumy_sentiment_by_professor, sumy_sentiment_by_class])\n",
    "professor_errors = errors[0]\n",
    "class_errors = errors[1]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "professor_absolute_error_list = professor_errors['absolute_error_list']\n",
    "mean_absolute_error = np.mean(professor_absolute_error_list)\n",
    "median_absolute_error = np.median(professor_absolute_error_list)\n",
    "std_dev_absolute_error = np.std(professor_absolute_error_list)\n",
    "print(\"Professor Summary Evaluation\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error}\")\n",
    "print(f\"Median Absolute Error: {median_absolute_error}\")\n",
    "print(f\"Standard Deviation of Absolute Error: {std_dev_absolute_error}\")\n",
    "\n",
    "class_absolute_error_list = class_errors['absolute_error_list']\n",
    "mean_absolute_error = np.mean(class_absolute_error_list)\n",
    "median_absolute_error = np.median(class_absolute_error_list)\n",
    "std_dev_absolute_error = np.std(class_absolute_error_list)\n",
    "\n",
    "print(\"Class Summary Evaluation\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error}\")\n",
    "print(f\"Median Absolute Error: {median_absolute_error}\")\n",
    "print(f\"Standard Deviation of Absolute Error: {std_dev_absolute_error}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use modern approach with LLM to summarize reviews\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
